{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import essential library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data and split it into dataset and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "\tlines = []\n",
    "\twith open(file, 'r') as f:\n",
    "\t\tfor line in f.readlines():\n",
    "\t\t\tline = line.strip().split(',')\n",
    "\t\t\tlines.append(line)\n",
    "\tlines = np.array(lines).astype(np.float32)\n",
    "\tdataset = lines[...,0:57]\n",
    "\tlabel = lines[...,57].astype(np.int8)\n",
    "\treturn dataset, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data\n",
    "### The given data has different data range. So we have to standardize and normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "\t### preprocessing the data to [0, 1]\n",
    "\tfrom sklearn import preprocessing\n",
    "\tscaler = preprocessing.MinMaxScaler(feature_range=(0, 1)).fit(data)\n",
    "\tdata = scaler.transform(data)\n",
    "\t### normalization\n",
    "\tdata = preprocessing.normalize(data, norm='l2')\n",
    "\t### PCA: the result shows no improvement\n",
    "\t# from sklearn.decomposition import PCA\n",
    "\t# data = PCA(n_components = 57).fit_transform(data)\n",
    "\treturn data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine Classifier\n",
    "### linear kernel gives the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_model():\n",
    "\tfrom sklearn.svm import SVC\n",
    "\tmodel = SVC(C = 1.5, kernel = 'linear', gamma = 'auto')\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer Perceptron Classifier\n",
    "### Perform better than the svm classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model():\n",
    "\tfrom sklearn.neural_network import MLPClassifier\n",
    "\tmodel = MLPClassifier(activation='relu', solver='adam', alpha=0.0001, max_iter=200, learning_rate_init=0.001)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the table of Accuracy, Precision, Recall, FP Rate, FN Rate, Overall Error Rate and Average Error Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table(cv_results, k, d):\n",
    "\ttp = cv_results['test_tp']\n",
    "\tfp = cv_results['test_fp']\n",
    "\ttn = cv_results['test_tn']\n",
    "\tfn = cv_results['test_fn']\n",
    "\tfrom prettytable import PrettyTable\n",
    "\tt = PrettyTable()\n",
    "\tt.add_column(\"Accuracy\", np.around( cv_results['test_Accuracy'] , decimals = d))\n",
    "\tt.add_column(\"Precision\", np.around( cv_results['test_Precision'] , decimals = d))\n",
    "\tt.add_column(\"Recall\", np.around( cv_results['test_Recall'] , decimals = d))\n",
    "\t### the false positive rate is the fraction of non-spam testing examples that are misclassified as spam\n",
    "\t### fp / ( fp + tn ) \n",
    "\tt.add_column(\"FP Rate\", np.around( fp / ( fp + tn ) , decimals = d))\n",
    "\t### the false negative rate is the fraction of spam testing examples that are misclassified as nonspam\n",
    "\t### fn / ( fn + tp ) = 1 - recall rate\n",
    "\tt.add_column(\"FN Rate\", np.around( fn / ( fn + tp ) , decimals = d))\n",
    "\t### the overall error rate is the fraction of overall examples that are misclassified. \n",
    "\tt.add_column(\"Overall Error Rate\", np.around( 1 - cv_results['test_Accuracy'] , decimals = d))\n",
    "\taverage_error = np.round(np.average(1 - cv_results['test_Accuracy']), decimals = d)\n",
    "\tt.add_column(\"Average ER\", [average_error]*k)\n",
    "\tprint(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "\tfrom sklearn.externals import joblib\n",
    "\tjoblib.dump(model, 'model.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------+---------+---------+--------------------+------------+\n",
      "| Accuracy | Precision |  Recall | FP Rate | FN Rate | Overall Error Rate | Average ER |\n",
      "+----------+-----------+---------+---------+---------+--------------------+------------+\n",
      "| 0.92842  |  0.93064  | 0.88462 | 0.04301 | 0.11538 |      0.07158       |   0.0748   |\n",
      "| 0.94143  |   0.9235  | 0.92857 | 0.05018 | 0.07143 |      0.05857       |   0.0748   |\n",
      "| 0.93709  |   0.9322  | 0.90659 | 0.04301 | 0.09341 |      0.06291       |   0.0748   |\n",
      "| 0.93913  |  0.93714  | 0.90608 | 0.03943 | 0.09392 |      0.06087       |   0.0748   |\n",
      "| 0.94348  |   0.9235  |  0.9337 | 0.05018 |  0.0663 |      0.05652       |   0.0748   |\n",
      "|  0.9413  |   0.885   |  0.9779 | 0.08244 |  0.0221 |       0.0587       |   0.0748   |\n",
      "| 0.95217  |  0.97041  | 0.90608 | 0.01792 | 0.09392 |      0.04783       |   0.0748   |\n",
      "| 0.93696  |  0.91304  | 0.92818 | 0.05735 | 0.07182 |      0.06304       |   0.0748   |\n",
      "| 0.87582  |    0.81   | 0.89503 | 0.13669 | 0.10497 |      0.12418       |   0.0748   |\n",
      "| 0.85621  |  0.83237  | 0.79558 | 0.10432 | 0.20442 |      0.14379       |   0.0748   |\n",
      "+----------+-----------+---------+---------+---------+--------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\tX, y = load_data(\"spambase.data\")\n",
    "\tX = preprocessing(X)\n",
    "\t### k-fold\n",
    "\tk = 10\n",
    "\t### choose from svm and NN\n",
    "\tmodel = svm_model()\n",
    "\t# model = NN_model()\n",
    "\tfrom sklearn.model_selection import cross_validate\n",
    "\tfrom sklearn.metrics import make_scorer, accuracy_score\n",
    "\tfrom sklearn.metrics import confusion_matrix\n",
    "\t### compute tn, fp, fn, tp\n",
    "\tdef tn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 0]\n",
    "\tdef fp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 1]\n",
    "\tdef fn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 0]\n",
    "\tdef tp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 1]\n",
    "\tscoring = {'Accuracy': 'accuracy', 'Precision': 'precision', 'Recall': 'recall',\n",
    "\t\t\t\t'tp': make_scorer(tp), 'tn': make_scorer(tn),\n",
    "\t\t\t\t'fp': make_scorer(fp), 'fn': make_scorer(fn)}\n",
    "    ### This cross-validation object is a variation of KFold that returns stratified folds. \n",
    "    ### The folds are made by preserving the percentage of samples for each class.\n",
    "\tcv_results = cross_validate(model, X, y, scoring = scoring, cv = k, n_jobs = -1,\n",
    "\t\t\t\t\t\treturn_train_score=False)\n",
    "\ttable(cv_results, k, 5)\n",
    "\t\n",
    "\t### save model\n",
    "\t# save_model(svm_model)\n",
    "\t\n",
    "if __name__ == '__main__':\n",
    "\tmain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
